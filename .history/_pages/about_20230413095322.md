---
layout: about
title: About
permalink: /

profile:
  align: right
  image: me.jpg
  # bio: 
  #     Shanghai, China <br>

news: false  # includes a list of news items
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I am currently a fourth-year PhD student in computer science at SJTU, advised by Prof. [Xinbing Wang](https://www.cs.sjtu.edu.cn/~wang-xb/) and Prof. [Haiming Jin](https://jhc.sjtu.edu.cn/~haimingjin/). I also work closely with Prof. [Weinan Zhang](https://wnzhang.net/). Previously, I was an undergraduate in the Department of Electrical and Information Engineering in Beijing Jiao Tong University.

My research centers around time series forecasting, spatial-temporal data mining and their broad applications (e.g., traffic prediction, knowledge graph reasoning). I am also interested in the interpretability study of deep forecasting model.

## Education

* Ph.D. of Computer Science, [Shanghai Jiaotong University](https://en.sjtu.edu.cn/), 2018 - now
* B.S. of Communication Enginering (Pilot Class), [Beijing Jiaotong University](http://en.njtu.edu.cn/), 2014 - 2018

---
## News
* <span style="color:red">New!!</span> I was competiting in the ultimate coding challenge [ReadyTraderGo](https://readytradergo.optiver.com/)

* Welcome to use our new released knowledge graph based semantic search system designed for the [DDE](https://www.ddeworld.org/) project。  
The system is online here - [AceKG Seach System](https://search.acekg.cn). :sparkles: :smile:

---
## Publications
<ul>
    <li><strong><a href="https://arxiv.org/abs/2202.07184">On the Origins of the Block Structure Phenomenon in Neural Networks</a></strong>
      <ul>
        <li>Thao Nguyen, Maithra Raghu, Simon Kornblith</li>
        <li><em>Preprint</em></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/2107.12580">Pointer Value Retrieval: A new benchmark for understanding the limits of neural network generalization</a></strong>
      <ul>
        <li>Chiyuan Zhang*, Maithra Raghu*, Jon Kleinberg, Samy Bengio</li>
        <li><em>Preprint</em></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/2108.08810">Do Vision Transformers See Like Convolutional Neural Networks?</a></strong>
      <ul>
        <li>Maithra Raghu, Thomas Unterthiner, Simon Kornblith, Chiyuan Zhang, Alexey Dosovitsky</li>
        <li><strong>Advances in Neural Information Processing Systems (NeurIPS) 2021</strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/2011.03037">Teaching with Commentaries</a></strong>
      <ul>
        <li>Aniruddh Raghu, Maithra Raghu, Simon Kornblith, David Duvenaud, Geoffrey Hinton</li>
        <li><strong>International Conference on Learning Representations (ICLR) 2021</strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/2010.15327">Do Wide and Deep Neural Networks Learn the Same Things? Uncovering How Neural Network Representations Vary with Width and Depth</a></strong>
      <ul>
        <li>Thao Nguyen, Maithra Raghu, Simon Kornblith</li>
        <li><strong>International Conference on Learning Representations (ICLR) 2021</strong></li>
        <li>Also appeared in <em>NeurIPS 2020 Workshop on Inductive Biases</em> and <em>WiML 2020</em></li>
        <li><strong><a href="https://www.youtube.com/watch?v=6uPop547u_E&amp;ab_channel=Weights%26Biases">Talk</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/2007.07400">Anatomy of Catastrophic Forgetting: Hidden Representations and Task Semantics</a></strong>
      <ul>
        <li>Vinay Ramasesh, Ethan Dyer, Maithra Raghu</li>
        <li><strong>International Conference on Learning Representations (ICLR) 2021</strong></li>
        <li>Also <strong>Best Paper ICML 2020 Workshop on Continual Learning</strong></li>
      </ul>
    </li>
    <li><strong><a href="https://maithraraghu.com/assets/files/thesis_final.pdf">Insights on Deep Representations for Machine Learning Systems and Human Collaborations</a></strong>
      <ul>
        <li>Maithra Raghu</li>
        <li><strong>PhD Thesis</strong></li>
        <li><strong><a href="https://maithraraghu.com/assets/files/thesis_defense_video.mp4">Video</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/2003.11755">A Survey of Deep Learning for Scientific Discovery</a></strong>
      <ul>
        <li>Maithra Raghu, Eric Schmidt</li>
        <li><em>Preprint</em></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1909.09157">Rapid Learning or Feature Reuse? Towards Understanding the Effectiveness of MAML</a></strong>
      <ul>
        <li>Aniruddh Raghu*, Maithra Raghu*, Samy Bengio, Oriol Vinayls <em>(*equal contribution)</em></li>
        <li><strong>International Conference on Learning Representations (ICLR) 2020</strong></li>
        <li><strong><a href="https://maithraraghu.com/assets/files/RapidLearningFeatureReuse.pdf">Poster</a></strong>, <strong><a href="https://maithraraghu.com/assets/files/ICLR2020_ANIL.pdf">Slides</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1902.07208">Transfusion: Understanding Transfer Learning with Applications to Medical Imaging</a></strong>
      <ul>
        <li>Maithra Raghu*, Chiyuan Zhang*, Jon Kleinberg<sup>†</sup>, Samy Bengio<sup>†</sup> <em>(*equal contribution)</em> <em>(</em><sup>†</sup><em>equal contribution)</em></li>
        <li><strong>Neural Information Processing Systems (NeurIPS), 2019</strong></li>
        <li>Also <a href="https://t.co/GaRJMkTPp1">oral presentation</a> in <em>NeurIPS ML for Health Workshop, 2019</em></li>
        <li><strong><a href="https://ai.googleblog.com/2019/12/understanding-transfer-learning-for.html">Blogpost</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1903.12220">The Algorithmic Automation Problem: Prediction, Triage and Human Effort</a></strong>
      <ul>
        <li>Maithra Raghu, Katy Blumer, Greg Corrado, Jon Kleinberg, Ziad Obermeyer, Sendhil Mullainathan</li>
        <li><strong>Workshop on Machine Learning for Health (ML4H), NeurIPS 2018</strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1807.01771">Direct Uncertainty Prediction for Medical Second Opinions</a></strong>
      <ul>
        <li>Maithra Raghu*, Katy Blumer*, Rory Sayres, Ziad Obermeyer, Sendhil Mullainathan, Jon Kleinberg <em>(*equal contribution)</em></li>
        <li><strong>International Conference on Machine Learning (ICML), 2019</strong></li>
        <li><strong><a href="https://maithraraghu.com/blog/2019/Direct_Uncertainty_Prediction/">Blogpost</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1806.05759">Insights on Representational Similarity in Neural Networks with Canonical Correlation</a></strong>
      <ul>
        <li>Ari Morcos*, Maithra Raghu*, Samy Bengio <em>(*equal contribution)</em></li>
        <li><strong>Advances in Neural Information Processing Systems (NeurIPS), 2018</strong></li>
        <li><strong><a href="https://github.com/google/svcca/">Code</a></strong>, <strong><a href="https://ai.googleblog.com/2018/06/how-can-neural-network-similarity-help.html">Blogpost</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1801.02774">Adversarial Spheres</a></strong>
      <ul>
        <li>Justin Gilmer, Luke Metz, Fartash Faghri, Samuel S. Schoenholz, Maithra Raghu, Martin Wattenberg, Ian Goodfellow</li>
        <li><em>Preprint</em></li>
        <li>Appeared in <strong>International Conference on Learning Representations (ICLR) Workshop, 2018</strong></li>
      </ul>
    </li>
    <li><strong><a href="http://arxiv.org/abs/1711.02301">Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?</a></strong>
      <ul>
        <li>Maithra Raghu, Alex Irpan, Jacob Andreas, Robert Kleinberg, Quoc V. Le, Jon Kleinberg</li>
        <li><strong>International Conference on Machine Learning (ICML), 2018</strong></li>
        <li>Also appeared in <strong>International Conference on Learning Representations (ICLR) Workshop, 2018</strong></li>
        <li><strong><a href="https://github.com/rubai5/ESS_Game">Code</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1706.05806">SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability</a></strong>
      <ul>
        <li>Maithra Raghu, Justin Gilmer, Jason Yosinski, Jascha Sohl-Dickstein</li>
        <li><strong>Advances in Neural Information Processing Systems (NeurIPS), 2017</strong></li>
        <li><strong><a href="https://github.com/google/svcca/">Code</a></strong>, <strong><a href="https://ai.googleblog.com/2017/11/interpreting-deep-neural-networks-with.html">Blogpost</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://openreview.net/forum?id=HkXKUTVFl">Explaining the Learning Dynamics of Direct Feedback Alignment</a></strong>
      <ul>
        <li>Justin Gilmer, Colin Raffel, Samuel S. Schoenholz, Maithra Raghu, Jascha Sohl-Dickstein</li>
        <li>Appeared in <strong>International Conference on Learning Representations (ICLR) Workshop, 2017</strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1606.05336">On the Expressive Power of Deep Neural Networks</a></strong>
      <ul>
        <li>Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, Jascha Sohl-Dickstein</li>
        <li><strong>International Conference on Machine Learning (ICML), 2017</strong></li>
        <li><strong><a href="https://vimeo.com/237276052">Video</a></strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1704.01255">Linear Additive Markov Processes</a></strong>
      <ul>
        <li>Ravi Kumar, Maithra Raghu, Tamas Sarlos, Andrew Tomkins <em>(alphabetical order)</em></li>
        <li><strong>World Wide Web Conference (WWW), 2017</strong></li>
      </ul>
    </li>
    <li><strong><a href="http://papers.nips.cc/paper/6322-exponential-expressivity-in-deep-neural-networks-through-transient-chaos">Exponential expressivity in deep neural networks through transient chaos</a></strong>
      <ul>
        <li>Ben Poole, Subhaneil Lahiri, Maithra Raghu, Jascha Sohl-Dickstein, Surya Ganguli</li>
        <li><strong>Advances in Neural Information Processing Systems (NeurIPS) 2016</strong></li>
      </ul>
    </li>
    <li><strong><a href="https://arxiv.org/abs/1506.00147">Team Performance with Test Scores</a></strong>
      <ul>
        <li>Jon Kleinberg, Maithra Raghu <em>(alphabetical order)</em></li>
        <li><strong>Economics and Computation (EC) 2015</strong></li>
        <li><strong>Invited to special issue of ACM Transactions on Economics and Computation, 2018</strong></li>
      </ul>
    </li>
  </ul>

* <strong><a href="https://arxiv.org/abs/2202.07184">On the Origins of the Block Structure Phenomenon in Neural Networks</a></strong>
* Yi Xu, **Junjie Ou**, Hui Xu, Luoyi Fu.<font color=DeepSkyBlue>Temporal Knowledge Graph Reasoning with Historical Contrastive Learning.</font>  
  <strong>AAAI 23: The 37th AAAI Conference on Artificial Intelligence.</strong> [paper link](https://arxiv.org/abs/2211.10904)

* **Ou, Junjie** and Sun, Jiahui and Zhu, Yichen and Jin, Haiming and Liu, Yijuan and Zhang, Fan and Huang, Jianqiang and Wang, Xinbing.<font color=DeepSkyBlue>STP-TrellisNets+: Spatial-Temporal Parallel TrellisNets for Multi-Step Metro Station Passenger Flow Prediction.</font>  
  <strong>TKDE 21: IEEE Transactions on Knowledge and Data Engineering.</strong> [paper link](https://ieeexplore.ieee.org/document/9813413)

* **Ou, Junjie** and Sun, Jiahui and Zhu, Yichen and Jin, Haiming and Liu, Yijuan and Zhang, Fan and Huang, Jianqiang and Wang, Xinbing. <font color=DeepSkyBlue>STP-TrellisNets: Spatial-Temporal Parallel TrellisNets for Metro Station Passenger Flow Prediction.</font>  
  <strong>CIKM 20: Proceedings of the 29th ACM International Conference on Information & Knowledge Management.</strong> [paper link](https://dl.acm.org/doi/10.1145/3340531.3411874)

* Yuhang YAO, **Junjie OU**, Yang LI, Luoyi FU, Xinbing WANG, Guihai CHEN.<font color=DeepSkyBlue>Turing index:cross-domain and cross-generation metric of unraveling scholars’ impact in academic big data.</font>  
  <strong>Big Data Research, 2019.</strong> [paper link](http://www.infocomm-journal.com/bdr/EN/abstract/article_169353.shtml)

---
## Teaching & Services

1. (TA) Engineering for Electronic Information (B). [[Course site]](https://www.cs.sjtu.edu.cn/~wang-xb/ieei/index.html)
-  EE101 Spring 2019-2020, SJTU IEEE Pilot Class
-  EE101 Winter 2020-2021, SJTU IEEE Pilot Class

2. Reviewers:
- SIGIR 22
- Infocom 21/22
- Mobicom 20
- [SCIENTIA SINICA Informationis](http://infocn.scichina.com)
- [Information Sciences](https://www.journals.elsevier.com/information-sciences)

---
## Misc.

By the way, my hobbies include singing :musical_score:, playing basketball :basketball: and working out in the gym :muscle:.
